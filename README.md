# Chats

Chat with Metaâ€™s Llama 2 on your MacBook without installing any other software or connecting to the internet. Save every conversation locally.

Features / TODO (roughly in order):
- [ ] Chat with Llama 2 7B without installing anything else
  - [x] hook agent up, save convos to coredata
  - [ ] server should shut down more reliably, try storing pids and reaping orphans
  - [ ] user can edit convo titles
  - [ ] TextField and NavigationLink focus behavior work more like Messages
  - [ ] make intel chips work by [making a universal `server` binary](https://developer.apple.com/documentation/apple-silicon/building-a-universal-macos-binary#Update-the-Architecture-List-of-Custom-Makefiles)

- [ ] Try any llama.cpp compatible model
- [ ] Change system prompts to modify personas or expertise
- [ ] Search conversations

